{
    "contents" : "#example of using NYT scraping functions to get and clean data\nsource(\"NYT_functions.R\")\nsection='\"Sports\"'\napikey=''\nsports=getMetaData(apikey = apikey, nrOfArticles = 2000, fq=makeFq(section))\nlength(unique(sports$urls))\n\n#Now to real business\n#sections from which we need articles\nsections=c('\"Sports\"', '\"Arts\"', '\"Business\"', '\"Obituaries\"', '\"World\"')\n\n#do it individually, because I've used most of my daily limit of 1000 calls\n#it takes time!!!\nsports=getMetaData(apikey = apikey, nrOfArticles = 3500, fq=makeFq(sections[1]))\narts=getMetaData(apikey = apikey, nrOfArticles = 3500, fq=makeFq(sections[2]))\nbusiness=getMetaData(apikey = apikey,beginDate = \"20130130\", \n                     nrOfArticles = 3400, fq=makeFq(sections[3]))\nobituaries=getMetaData(apikey = apikey, nrOfArticles = 2400,\n                       fq=makeFq(sections[4]),dayStep = 2000,\n                       beginDate = \"20160601\")\nworld=getMetaData(apikey = apikey, nrOfArticles = 3200, fq=makeFq(sections[5]))\n\n##get articles body, no scraping limit here, it takes time!!!\nsports_body=getArticleBody(articleUrls = sports$urls)\nsports$body=sports_body\n\narts_body=getArticleBody(articleUrls = arts$urls)\narts$body=arts_body\n\nbusiness_body=getArticleBody(articleUrls = business$urls)\nbusiness$body=business_body\n\nobituaries_body=getArticleBody(articleUrls = obituaries$urls)\nobituaries$body=obituaries_body\n\nworld_body=getArticleBody(articleUrls = world$urls)\nworld$body=world_body\n\n#make list of dataframes\nallDataDfList=list(sports=sports, arts=arts, business=business,\n                   obituaries=obituaries, world=world)\n#save data as csv files\nlapply(1:length(allDataDfList), function(i)\n  write.csv(allDataDfList[[i]], \n            file = paste0(\"./articles/\",names(allDataDfList[i]), \".csv\"),\n            row.names = FALSE))\n#save it as .RData files\nlapply(names(allDataDfList), function(x) {\n  x1 <- allDataDfList[[x]]\n  save(x1, file=paste0(\"./articles/\", x, '.RData'))\n})\n\n#remove duplicates and keep first 2000 observations, remove rows where\n#body=NA\ndatadflist <- lapply(allDataDfList, function(df) {\n  df=df[!duplicated(df), ]\n  df=df[!is.na(df$body),]\n  df=df[1:2000,]\n  #add titles to text\n  df$bodyTitle=paste(df$titles, df$body)\n  df\n})\n#mark training and test set rows into data frames\ndatadflist <- lapply(datadflist, function(df) {\n  id=sample(x=2000, size=1000)\n  df$TrainTest=NA\n  df$TrainTest[id]=\"test\"\n  df$TrainTest[-id]=\"training\"\n  df\n})\n#make doc-term matrix on train data\nTrainMatrixList <- lapply(datadflist, function(df) {\n  docmatrix=DocMatrixMake(df[df$TrainTest==\"training\",])\n  list(df=docmatrix)\n})\n#lets also makse doc-term matrix on test data\nTestMatrixList <- lapply(datadflist, function(df) {\n  docmatrix=DocMatrixMake(df[df$TrainTest==\"test\",])\n  list(df=docmatrix)\n})\n#calculate probabilities for training data\nprobMatrixList=lapply(TrainMatrixList, function(Matrix) {\n  probMatrix=probabilityMatrix(as.matrix(Matrix$df))\n  list(probMatrix)\n})\n#loop through test data to get predictions\nresultsSports=c()\nfor(i in 1:nrow(TestMatrixList$sports$df)) {\n  #get cleaned words from test doc-term matrix\n  testChars<-names(data.frame(as.matrix(\n    TestMatrixList$sports$df[i, as.matrix(TestMatrixList$sports$df[i,])>0])))\n  testProb=sapply(probMatrixList, function(pMatrix,testChars=testChars) {\n    prob= getProbability(testChars,pMatrix)\n    prob\n  })\n  resultsSports[i]=names(testProb[testProb==max(testProb)])\n  cat(\"Worked on article nr\", i)\n}\n#get predicitons on individaul article categories\nresultsArts=predictResult(testMatrix=TestMatrixList$arts$df,\n                          probabilityMatrixList=probMatrixList) \n\nresultsBusiness=predictResult(testMatrix=TestMatrixList$business$df,\n                          probabilityMatrixList=probMatrixList) \n\nresultsObituaries=predictResult(testMatrix=TestMatrixList$obituaries$df,\n                              probabilityMatrixList=probMatrixList)\n\nresultsWorld=predictResult(testMatrix=TestMatrixList$world$df,\n                                probabilityMatrixList=probMatrixList)\n\n#try to make confusn matrix-like thing to plot the results\npredictedClasses=data.frame(predicted=c(resultsArts,resultsBusiness,\n                                        resultsSports,\n                                        resultsObituaries,resultsWorld ),\n                            real=c(rep(\"arts\",length(resultsArts)),\n                                   rep(\"business\",length(resultsBusiness)),\n                                   rep(\"sports\",length(resultsSports)),\n                                   rep(\"obituaries\",length(resultsObituaries)),\n                                   rep(\"world\",length(resultsWorld))))\n\nfinalMatrix=as.matrix(table(predictedClasses$predicted,predictedClasses$real))\n#plot it as heatmap\nlibrary(pheatmap)\n#colours for heatmap\nYlOrBr <- c('#f7fbff','#deebf7','#c6dbef','#9ecae1','#6baed6',\n            '#4292c6','#2171b5','#08519c','#08306b')\n#plot it\npheatmap(finalMatrix, cluster_rows = F, cluster_cols = F, display_numbers = T,\n         color=YlOrBr,fontsize=20,fontsize_number=15,number_format=\"%.0f\",\n         number_color=\"grey\")\n#accuracy\ncorrectNrOfArticles=c()\nfor(i in 1:ncol(finalMatrix)) {\n    correctNrOfArticles[i]=finalMatrix[i,i]\n}\nsum(correctNrOfArticles)/(5*1000)",
    "created" : 1467180777329.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "4195150801",
    "id" : "86AA4179",
    "lastKnownWriteTime" : 1467180928,
    "path" : "~/Lugemist/Doing Data Science OReilly/NY times/NY_times.R",
    "project_path" : "NY_times.R",
    "properties" : {
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "type" : "r_source"
}